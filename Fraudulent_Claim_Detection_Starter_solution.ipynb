{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJ6cv25EDPWV"
   },
   "source": [
    "## **Fraudulent Claim Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rLrWLwZDPWW"
   },
   "source": [
    "## Problem Statement\n",
    "Global Insure, a leading insurance company, processes thousands of claims annually. However, a significant percentage of these claims turn out to be fraudulent, resulting in considerable financial losses. The company’s current process for identifying fraudulent claims involves manual inspections, which is time-consuming and inefficient. Fraudulent claims are often detected too late in the process, after the company has already paid out significant amounts. Global Insure wants to improve its fraud detection process using data-driven insights to classify claims as fraudulent or legitimate early in the approval process. This would minimise financial losses and optimise the overall claims handling process.\n",
    "\n",
    "## Business Objective\n",
    "Global Insure wants to build a model to classify insurance claims as either fraudulent or legitimate based on historical claim details and customer profiles. By using features like claim amounts, customer profiles and claim types, the company aims to predict which claims are likely to be fraudulent before they are approved.\n",
    "\n",
    "\n",
    "Based on this assignment, you have to answer the following questions:<br>\n",
    "\n",
    "● How can we analyse historical claim data to detect patterns that indicate fraudulent claims?<br>\n",
    "● Which features are most predictive of fraudulent behaviour?<br>\n",
    "● Can we predict the likelihood of fraud for an incoming claim, based on past data?<br>\n",
    "● What insights can be drawn from the model that can help in improving the fraud detection process?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCp1H_XyDPWX"
   },
   "source": [
    "## Assignment Tasks\n",
    "You need to perform the following steps for successfully completing this assignment:\n",
    "1. Data Preparation\n",
    "2. Data Cleaning\n",
    "3. Train Validation Split 70-30\n",
    "4. EDA on Training Data\n",
    "5. EDA on Validation Data (optional)\n",
    "6. Feature Engineering\n",
    "7. Model Building\n",
    "8. Predicting and Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPnbScj6sHfw"
   },
   "source": [
    "## Data Dictionary\n",
    "The insurance claims data has 40 Columns and 1000 Rows. Following data dictionary provides the description for each column present in dataset:<br>\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Column Name</th>\n",
    "      <th>Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>months_as_customer</td>\n",
    "      <td>Represents the duration in months that a customer has been associated with the insurance company.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>age</td>\n",
    "      <td>Represents the age of the insured person.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>policy_number</td>\n",
    "      <td>Represents a unique identifier for each insurance policy.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>policy_bind_date</td>\n",
    "      <td>Represents the date when the insurance policy was initiated.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>policy_state</td>\n",
    "      <td>Represents the state where the insurance policy is applicable.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>policy_csl</td>\n",
    "      <td>Represents the combined single limit for the insurance policy.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>policy_deductable</td>\n",
    "      <td>Represents the amount that the insured person needs to pay before the insurance coverage kicks in.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>policy_annual_premium</td>\n",
    "      <td>Represents the yearly cost of the insurance policy.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>umbrella_limit</td>\n",
    "      <td>Represents an additional layer of liability coverage provided beyond the limits of the primary insurance policy.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>insured_zip</td>\n",
    "      <td>Represents the zip code of the insured person.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>insured_sex</td>\n",
    "      <td>Represents the gender of the insured person.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>insured_education_level</td>\n",
    "      <td>Represents the highest educational qualification of the insured person.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>insured_occupation</td>\n",
    "      <td>Represents the profession or job of the insured person.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>insured_hobbies</td>\n",
    "      <td>Represents the hobbies or leisure activities of the insured person.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>insured_relationship</td>\n",
    "      <td>Represents the relationship of the insured person to the policyholder.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>capital-gains</td>\n",
    "      <td>Represents the profit earned from the sale of assets such as stocks, bonds, or real estate.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>capital-loss</td>\n",
    "      <td>Represents the loss incurred from the sale of assets such as stocks, bonds, or real estate.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>incident_date</td>\n",
    "      <td>Represents the date when the incident or accident occurred.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>incident_type</td>\n",
    "      <td>Represents the category or type of incident that led to the claim.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>collision_type</td>\n",
    "      <td>Represents the type of collision that occurred in an accident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>incident_severity</td>\n",
    "      <td>Represents the extent of damage or injury caused by the incident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>authorities_contacted</td>\n",
    "      <td>Represents the authorities or agencies that were contacted after the incident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>incident_state</td>\n",
    "      <td>Represents the state where the incident occurred.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>incident_city</td>\n",
    "      <td>Represents the city where the incident occurred.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>incident_location</td>\n",
    "      <td>Represents the specific location or address where the incident occurred.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>incident_hour_of_the_day</td>\n",
    "      <td>Represents the hour of the day when the incident occurred.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>number_of_vehicles_involved</td>\n",
    "      <td>Represents the total number of vehicles involved in the incident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>property_damage</td>\n",
    "      <td>Represents whether there was any damage to property in the incident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>bodily_injuries</td>\n",
    "      <td>Represents the number of bodily injuries resulting from the incident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>witnesses</td>\n",
    "      <td>Represents the number of witnesses present at the scene of the incident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>police_report_available</td>\n",
    "      <td>Represents whether a police report is available for the incident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>total_claim_amount</td>\n",
    "      <td>Represents the total amount claimed by the insured person for the incident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>injury_claim</td>\n",
    "      <td>Represents the amount claimed for injuries sustained in the incident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>property_claim</td>\n",
    "      <td>Represents the amount claimed for property damage in the incident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>vehicle_claim</td>\n",
    "      <td>Represents the amount claimed for vehicle damage in the incident.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>auto_make</td>\n",
    "      <td>Represents the manufacturer of the insured vehicle.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>auto_model</td>\n",
    "      <td>Represents the specific model of the insured vehicle.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>auto_year</td>\n",
    "      <td>Represents the year of manufacture of the insured vehicle.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>fraud_reported</td>\n",
    "      <td>Represents whether the claim was reported as fraudulent or not.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>_c39</td>\n",
    "      <td>Represents an unknown or unspecified variable.</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Hfg3nHjDPWY"
   },
   "source": [
    "## **1. Data Preparation**\n",
    "In this step, read the dataset provided in CSV format and look at basic statistics of the data, including preview of data, dimension of data, column descriptions and data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xZBs5L_DPWY"
   },
   "source": [
    "### **1.0 Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2xUZYP92DPWY"
   },
   "outputs": [],
   "source": [
    "# Supress unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6glz5HkPDPWZ"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8-RBUdWDPWZ"
   },
   "source": [
    "### **1.1 Load the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kP0JaSjJDPWZ"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df=pd.read_csv(\"insurance_claims.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qaR4TkqTDPWZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "2                 134   29         687698       2000-09-06           OH   \n",
       "3                 256   41         227811       1990-05-25           IL   \n",
       "4                 228   44         367455       2014-06-06           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
       "0       466132  ...                     YES              71610         6510   \n",
       "1       468176  ...                       ?               5070          780   \n",
       "2       430632  ...                      NO              34650         7700   \n",
       "3       608117  ...                      NO              63400         6340   \n",
       "4       610706  ...                      NO               6500         1300   \n",
       "\n",
       "  property_claim vehicle_claim  auto_make  auto_model auto_year  \\\n",
       "0          13020         52080       Saab         92x      2004   \n",
       "1            780          3510   Mercedes        E400      2007   \n",
       "2           3850         23100      Dodge         RAM      2007   \n",
       "3           6340         50720  Chevrolet       Tahoe      2014   \n",
       "4            650          4550     Accura         RSX      2009   \n",
       "\n",
       "  fraud_reported _c39  \n",
       "0              Y  NaN  \n",
       "1              Y  NaN  \n",
       "2              N  NaN  \n",
       "3              Y  NaN  \n",
       "4              N  NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check at the first few entries\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TK9_lipzDPWa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Fd0PADNIuqov"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 40 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   months_as_customer           1000 non-null   int64  \n",
      " 1   age                          1000 non-null   int64  \n",
      " 2   policy_number                1000 non-null   int64  \n",
      " 3   policy_bind_date             1000 non-null   object \n",
      " 4   policy_state                 1000 non-null   object \n",
      " 5   policy_csl                   1000 non-null   object \n",
      " 6   policy_deductable            1000 non-null   int64  \n",
      " 7   policy_annual_premium        1000 non-null   float64\n",
      " 8   umbrella_limit               1000 non-null   int64  \n",
      " 9   insured_zip                  1000 non-null   int64  \n",
      " 10  insured_sex                  1000 non-null   object \n",
      " 11  insured_education_level      1000 non-null   object \n",
      " 12  insured_occupation           1000 non-null   object \n",
      " 13  insured_hobbies              1000 non-null   object \n",
      " 14  insured_relationship         1000 non-null   object \n",
      " 15  capital-gains                1000 non-null   int64  \n",
      " 16  capital-loss                 1000 non-null   int64  \n",
      " 17  incident_date                1000 non-null   object \n",
      " 18  incident_type                1000 non-null   object \n",
      " 19  collision_type               1000 non-null   object \n",
      " 20  incident_severity            1000 non-null   object \n",
      " 21  authorities_contacted        909 non-null    object \n",
      " 22  incident_state               1000 non-null   object \n",
      " 23  incident_city                1000 non-null   object \n",
      " 24  incident_location            1000 non-null   object \n",
      " 25  incident_hour_of_the_day     1000 non-null   int64  \n",
      " 26  number_of_vehicles_involved  1000 non-null   int64  \n",
      " 27  property_damage              1000 non-null   object \n",
      " 28  bodily_injuries              1000 non-null   int64  \n",
      " 29  witnesses                    1000 non-null   int64  \n",
      " 30  police_report_available      1000 non-null   object \n",
      " 31  total_claim_amount           1000 non-null   int64  \n",
      " 32  injury_claim                 1000 non-null   int64  \n",
      " 33  property_claim               1000 non-null   int64  \n",
      " 34  vehicle_claim                1000 non-null   int64  \n",
      " 35  auto_make                    1000 non-null   object \n",
      " 36  auto_model                   1000 non-null   object \n",
      " 37  auto_year                    1000 non-null   int64  \n",
      " 38  fraud_reported               1000 non-null   object \n",
      " 39  _c39                         0 non-null      float64\n",
      "dtypes: float64(2), int64(17), object(21)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Inspect the features in the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRijmf2EDPWa"
   },
   "source": [
    "## **2. Data Cleaning** <font color = red>[10 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxXOACINDPWa"
   },
   "source": [
    "### **2.1 Handle null values** <font color = red>[2 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJDjZSkmDPWa"
   },
   "source": [
    "#### **2.1.1** Examine the columns to determine if any value or column needs to be treated <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "3B4OtvQlDPWa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "months_as_customer              0\n",
       "age                             0\n",
       "policy_number                   0\n",
       "policy_bind_date                0\n",
       "policy_state                    0\n",
       "policy_csl                      0\n",
       "policy_deductable               0\n",
       "policy_annual_premium           0\n",
       "umbrella_limit                  0\n",
       "insured_zip                     0\n",
       "insured_sex                     0\n",
       "insured_education_level         0\n",
       "insured_occupation              0\n",
       "insured_hobbies                 0\n",
       "insured_relationship            0\n",
       "capital-gains                   0\n",
       "capital-loss                    0\n",
       "incident_date                   0\n",
       "incident_type                   0\n",
       "collision_type                  0\n",
       "incident_severity               0\n",
       "authorities_contacted          91\n",
       "incident_state                  0\n",
       "incident_city                   0\n",
       "incident_location               0\n",
       "incident_hour_of_the_day        0\n",
       "number_of_vehicles_involved     0\n",
       "property_damage                 0\n",
       "bodily_injuries                 0\n",
       "witnesses                       0\n",
       "police_report_available         0\n",
       "total_claim_amount              0\n",
       "injury_claim                    0\n",
       "property_claim                  0\n",
       "vehicle_claim                   0\n",
       "auto_make                       0\n",
       "auto_model                      0\n",
       "auto_year                       0\n",
       "fraud_reported                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of missing values in each column\n",
    "missing_value=df.isnull().sum()\n",
    "missing_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "months_as_customer               0\n",
      "age                              0\n",
      "policy_number                    0\n",
      "policy_bind_date                 0\n",
      "policy_state                     0\n",
      "policy_csl                       0\n",
      "policy_deductable                0\n",
      "policy_annual_premium            0\n",
      "umbrella_limit                   0\n",
      "insured_zip                      0\n",
      "insured_sex                      0\n",
      "insured_education_level          0\n",
      "insured_occupation               0\n",
      "insured_hobbies                  0\n",
      "insured_relationship             0\n",
      "capital-gains                    0\n",
      "capital-loss                     0\n",
      "incident_date                    0\n",
      "incident_type                    0\n",
      "collision_type                 178\n",
      "incident_severity                0\n",
      "authorities_contacted            0\n",
      "incident_state                   0\n",
      "incident_city                    0\n",
      "incident_location                0\n",
      "incident_hour_of_the_day         0\n",
      "number_of_vehicles_involved      0\n",
      "property_damage                360\n",
      "bodily_injuries                  0\n",
      "witnesses                        0\n",
      "police_report_available        343\n",
      "total_claim_amount               0\n",
      "injury_claim                     0\n",
      "property_claim                   0\n",
      "vehicle_claim                    0\n",
      "auto_make                        0\n",
      "auto_model                       0\n",
      "auto_year                        0\n",
      "fraud_reported                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[df == '?'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE6K2iqkDPWb"
   },
   "source": [
    "#### **2.1.2** Handle rows containing null values <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "88PX2r5hDPWb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
      "0                   328   48         521585       2014-10-17           OH   \n",
      "1                   228   42         342868       2006-06-27           IN   \n",
      "2                   134   29         687698       2000-09-06           OH   \n",
      "3                   256   41         227811       1990-05-25           IL   \n",
      "4                   228   44         367455       2014-06-06           IL   \n",
      "..                  ...  ...            ...              ...          ...   \n",
      "995                   3   38         941851       1991-07-16           OH   \n",
      "996                 285   41         186934       2014-01-05           IL   \n",
      "997                 130   34         918516       2003-02-17           OH   \n",
      "998                 458   62         533940       2011-11-18           IL   \n",
      "999                 456   60         556080       1996-11-11           OH   \n",
      "\n",
      "    policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
      "0      250/500               1000                1406.91               0   \n",
      "1      250/500               2000                1197.22         5000000   \n",
      "2      100/300               2000                1413.14         5000000   \n",
      "3      250/500               2000                1415.74         6000000   \n",
      "4     500/1000               1000                1583.91         6000000   \n",
      "..         ...                ...                    ...             ...   \n",
      "995   500/1000               1000                1310.80               0   \n",
      "996    100/300               1000                1436.79               0   \n",
      "997    250/500                500                1383.49         3000000   \n",
      "998   500/1000               2000                1356.92         5000000   \n",
      "999    250/500               1000                 766.19               0   \n",
      "\n",
      "     insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
      "0         466132  ...                     YES              71610         6510   \n",
      "1         468176  ...                       ?               5070          780   \n",
      "2         430632  ...                      NO              34650         7700   \n",
      "3         608117  ...                      NO              63400         6340   \n",
      "4         610706  ...                      NO               6500         1300   \n",
      "..           ...  ...                     ...                ...          ...   \n",
      "995       431289  ...                       ?              87200        17440   \n",
      "996       608177  ...                       ?             108480        18080   \n",
      "997       442797  ...                     YES              67500         7500   \n",
      "998       441714  ...                     YES              46980         5220   \n",
      "999       612260  ...                       ?               5060          460   \n",
      "\n",
      "    property_claim vehicle_claim   auto_make  auto_model auto_year  \\\n",
      "0            13020         52080        Saab         92x      2004   \n",
      "1              780          3510    Mercedes        E400      2007   \n",
      "2             3850         23100       Dodge         RAM      2007   \n",
      "3             6340         50720   Chevrolet       Tahoe      2014   \n",
      "4              650          4550      Accura         RSX      2009   \n",
      "..             ...           ...         ...         ...       ...   \n",
      "995           8720         61040       Honda      Accord      2006   \n",
      "996          18080         72320  Volkswagen      Passat      2015   \n",
      "997           7500         52500      Suburu     Impreza      1996   \n",
      "998           5220         36540        Audi          A5      1998   \n",
      "999            920          3680    Mercedes        E400      2007   \n",
      "\n",
      "    fraud_reported _c39  \n",
      "0                Y  NaN  \n",
      "1                Y  NaN  \n",
      "2                N  NaN  \n",
      "3                Y  NaN  \n",
      "4                N  NaN  \n",
      "..             ...  ...  \n",
      "995              N  NaN  \n",
      "996              N  NaN  \n",
      "997              N  NaN  \n",
      "998              N  NaN  \n",
      "999              N  NaN  \n",
      "\n",
      "[1000 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# Handle the rows containing null values\n",
    "rows_with_missing = df[df.isnull().any(axis=1)]\n",
    "print(rows_with_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "202JyqOjDPWb"
   },
   "source": [
    "### **2.2 Identify and handle redundant values and columns** <font color = red>[5 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSh2wYZoDPWb"
   },
   "source": [
    "#### **2.2.1** Examine the columns to determine if any value or column needs to be treated <font color=\"red\">[2 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3009,
   "metadata": {
    "id": "1x0Cn8BiDPWb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      YES\n",
       "1      NaN\n",
       "2       NO\n",
       "3      NaN\n",
       "4       NO\n",
       "      ... \n",
       "995    YES\n",
       "996    YES\n",
       "997    NaN\n",
       "998    NaN\n",
       "999    NaN\n",
       "Name: property_damage, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 3009,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write code to display all the columns with their unique values and counts and check for redundant values\n",
    "# Column property_damage and police_report need to fill the '?'\n",
    "# Replacing '?' with NA and then filling NA with medain value\n",
    "\n",
    "df['property_damage'] = df['property_damage'].replace('?', np.nan)\n",
    "df['police_report_available'] = df['police_report_available'].replace('?', np.nan)\n",
    "df['collision_type']=df['collision_type'].replace('?', np.nan)\n",
    "df['property_damage']                                           \n",
    "\n",
    "\n",
    "\n",
    "#df['police_report_available'] = df['police_report_available'].replace('?', np.nan)\n",
    "#df['police_report_available']\n",
    "#df['collision_type']=df['collision_type'].replace('?', np.nan)\n",
    "\n",
    "##df['police_report_available'] = df['police_report_available'].astype(\"float64\")\n",
    "\n",
    "# Median\n",
    "#df['collision_type'].fillna(df['collision_type'].median(), inplace=True)\n",
    "#df['property_damage']=df['property_damage'].fillna(df['property_damage'].median())\n",
    "#df['police_report_available'] = df['police_report_available'].fillna(df['police_report_available'].median())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRIhr3ZwDPWb"
   },
   "source": [
    "#### **2.2.2** Identify and drop any columns that are completely empty <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "9vLZf8ExDPWb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "2                 134   29         687698       2000-09-06           OH   \n",
       "3                 256   41         227811       1990-05-25           IL   \n",
       "4                 228   44         367455       2014-06-06           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip  ... witnesses police_report_available total_claim_amount  \\\n",
       "0       466132  ...         2                     YES              71610   \n",
       "1       468176  ...         0                       ?               5070   \n",
       "2       430632  ...         3                      NO              34650   \n",
       "3       608117  ...         2                      NO              63400   \n",
       "4       610706  ...         1                      NO               6500   \n",
       "\n",
       "  injury_claim property_claim  vehicle_claim  auto_make auto_model auto_year  \\\n",
       "0         6510          13020          52080       Saab        92x      2004   \n",
       "1          780            780           3510   Mercedes       E400      2007   \n",
       "2         7700           3850          23100      Dodge        RAM      2007   \n",
       "3         6340           6340          50720  Chevrolet      Tahoe      2014   \n",
       "4         1300            650           4550     Accura        RSX      2009   \n",
       "\n",
       "  fraud_reported  \n",
       "0              Y  \n",
       "1              Y  \n",
       "2              N  \n",
       "3              Y  \n",
       "4              N  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify and drop any columns that are completely empty\n",
    "df=df.drop(\"_c39\",axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "months_as_customer             0.0\n",
       "age                            0.0\n",
       "policy_number                  0.0\n",
       "policy_bind_date               0.0\n",
       "policy_state                   0.0\n",
       "policy_csl                     0.0\n",
       "policy_deductable              0.0\n",
       "policy_annual_premium          0.0\n",
       "umbrella_limit                 0.0\n",
       "insured_zip                    0.0\n",
       "insured_sex                    0.0\n",
       "insured_education_level        0.0\n",
       "insured_occupation             0.0\n",
       "insured_hobbies                0.0\n",
       "insured_relationship           0.0\n",
       "capital-gains                  0.0\n",
       "capital-loss                   0.0\n",
       "incident_date                  0.0\n",
       "incident_type                  0.0\n",
       "collision_type                 0.0\n",
       "incident_severity              0.0\n",
       "authorities_contacted          9.1\n",
       "incident_state                 0.0\n",
       "incident_city                  0.0\n",
       "incident_location              0.0\n",
       "incident_hour_of_the_day       0.0\n",
       "number_of_vehicles_involved    0.0\n",
       "property_damage                0.0\n",
       "bodily_injuries                0.0\n",
       "witnesses                      0.0\n",
       "police_report_available        0.0\n",
       "total_claim_amount             0.0\n",
       "injury_claim                   0.0\n",
       "property_claim                 0.0\n",
       "vehicle_claim                  0.0\n",
       "auto_make                      0.0\n",
       "auto_model                     0.0\n",
       "auto_year                      0.0\n",
       "fraud_reported                 0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()*100/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorities_contacted\n",
       "Police       292\n",
       "Fire         223\n",
       "Other        198\n",
       "Ambulance    196\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['authorities_contacted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Cx8douODPWd"
   },
   "source": [
    "#### **2.2.3** Identify and drop rows where features have illogical or invalid values, such as negative values for features that should only have positive values <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3013,
   "metadata": {
    "id": "U5oARc23DPWd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 38 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   months_as_customer           1000 non-null   int64  \n",
      " 1   age                          1000 non-null   int64  \n",
      " 2   policy_number                1000 non-null   int64  \n",
      " 3   policy_bind_date             1000 non-null   object \n",
      " 4   policy_state                 1000 non-null   object \n",
      " 5   policy_csl                   1000 non-null   object \n",
      " 6   policy_deductable            1000 non-null   int64  \n",
      " 7   policy_annual_premium        1000 non-null   float64\n",
      " 8   umbrella_limit               1000 non-null   int64  \n",
      " 9   insured_zip                  1000 non-null   int64  \n",
      " 10  insured_sex                  1000 non-null   object \n",
      " 11  insured_education_level      1000 non-null   object \n",
      " 12  insured_occupation           1000 non-null   object \n",
      " 13  insured_hobbies              1000 non-null   object \n",
      " 14  insured_relationship         1000 non-null   object \n",
      " 15  capital-gains                1000 non-null   int64  \n",
      " 16  incident_date                1000 non-null   object \n",
      " 17  incident_type                1000 non-null   object \n",
      " 18  collision_type               822 non-null    object \n",
      " 19  incident_severity            1000 non-null   object \n",
      " 20  authorities_contacted        909 non-null    object \n",
      " 21  incident_state               1000 non-null   object \n",
      " 22  incident_city                1000 non-null   object \n",
      " 23  incident_location            1000 non-null   object \n",
      " 24  incident_hour_of_the_day     1000 non-null   int64  \n",
      " 25  number_of_vehicles_involved  1000 non-null   int64  \n",
      " 26  property_damage              640 non-null    object \n",
      " 27  bodily_injuries              1000 non-null   int64  \n",
      " 28  witnesses                    1000 non-null   int64  \n",
      " 29  police_report_available      657 non-null    object \n",
      " 30  total_claim_amount           1000 non-null   int64  \n",
      " 31  injury_claim                 1000 non-null   int64  \n",
      " 32  property_claim               1000 non-null   int64  \n",
      " 33  vehicle_claim                1000 non-null   int64  \n",
      " 34  auto_make                    1000 non-null   object \n",
      " 35  auto_model                   1000 non-null   object \n",
      " 36  auto_year                    1000 non-null   int64  \n",
      " 37  fraud_reported               1000 non-null   object \n",
      "dtypes: float64(1), int64(16), object(21)\n",
      "memory usage: 297.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Identify and drop rows where features have illogical or invalid values, such as negative values for features that should only have positive values\n",
    "df=df.drop(\"capital-loss\",axis=1)  \n",
    "## Capital loss column has to have values in positive because column itslef is named as loss hence removing the feature\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTGMKeeNDPWd"
   },
   "source": [
    "#### **2.2.4** Identify and remove columns where a large proportion of the values are unique or near-unique, as these columns are likely to be identifiers or have very limited predictive power <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3015,
   "metadata": {
    "id": "U4LXO65UDPWd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 35 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   months_as_customer           1000 non-null   int64  \n",
      " 1   age                          1000 non-null   int64  \n",
      " 2   policy_number                1000 non-null   int64  \n",
      " 3   policy_bind_date             1000 non-null   object \n",
      " 4   policy_state                 1000 non-null   object \n",
      " 5   policy_csl                   1000 non-null   object \n",
      " 6   policy_deductable            1000 non-null   int64  \n",
      " 7   policy_annual_premium        1000 non-null   float64\n",
      " 8   umbrella_limit               1000 non-null   int64  \n",
      " 9   insured_zip                  1000 non-null   int64  \n",
      " 10  insured_sex                  1000 non-null   object \n",
      " 11  insured_occupation           1000 non-null   object \n",
      " 12  insured_relationship         1000 non-null   object \n",
      " 13  capital-gains                1000 non-null   int64  \n",
      " 14  incident_date                1000 non-null   object \n",
      " 15  incident_type                1000 non-null   object \n",
      " 16  collision_type               822 non-null    object \n",
      " 17  incident_severity            1000 non-null   object \n",
      " 18  authorities_contacted        909 non-null    object \n",
      " 19  incident_state               1000 non-null   object \n",
      " 20  incident_city                1000 non-null   object \n",
      " 21  incident_location            1000 non-null   object \n",
      " 22  incident_hour_of_the_day     1000 non-null   int64  \n",
      " 23  number_of_vehicles_involved  1000 non-null   int64  \n",
      " 24  property_damage              640 non-null    object \n",
      " 25  bodily_injuries              1000 non-null   int64  \n",
      " 26  witnesses                    1000 non-null   int64  \n",
      " 27  police_report_available      657 non-null    object \n",
      " 28  total_claim_amount           1000 non-null   int64  \n",
      " 29  injury_claim                 1000 non-null   int64  \n",
      " 30  property_claim               1000 non-null   int64  \n",
      " 31  vehicle_claim                1000 non-null   int64  \n",
      " 32  auto_model                   1000 non-null   object \n",
      " 33  auto_year                    1000 non-null   int64  \n",
      " 34  fraud_reported               1000 non-null   object \n",
      "dtypes: float64(1), int64(16), object(18)\n",
      "memory usage: 273.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Identify and remove columns that are likely to be identifiers or have very limited predictive power\n",
    "df=df.drop(\"insured_hobbies\",axis=1)\n",
    "df=df.drop(\"insured_education_level\",axis=1)\n",
    "df=df.drop(\"auto_make\", axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3016,
   "metadata": {
    "id": "KzHx2BzPDPWd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>17-10-2014</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>27-06-2006</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>06-09-2000</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>25-05-1990</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>06-06-2014</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       17-10-2014           OH   \n",
       "1                 228   42         342868       27-06-2006           IN   \n",
       "2                 134   29         687698       06-09-2000           OH   \n",
       "3                 256   41         227811       25-05-1990           IL   \n",
       "4                 228   44         367455       06-06-2014           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip  ... bodily_injuries witnesses police_report_available  \\\n",
       "0       466132  ...               1         2                     YES   \n",
       "1       468176  ...               0         0                     NaN   \n",
       "2       430632  ...               2         3                      NO   \n",
       "3       608117  ...               1         2                      NO   \n",
       "4       610706  ...               0         1                      NO   \n",
       "\n",
       "   total_claim_amount injury_claim property_claim vehicle_claim auto_model  \\\n",
       "0               71610         6510          13020         52080        92x   \n",
       "1                5070          780            780          3510       E400   \n",
       "2               34650         7700           3850         23100        RAM   \n",
       "3               63400         6340           6340         50720      Tahoe   \n",
       "4                6500         1300            650          4550        RSX   \n",
       "\n",
       "  auto_year fraud_reported  \n",
       "0      2004              Y  \n",
       "1      2007              Y  \n",
       "2      2007              N  \n",
       "3      2014              Y  \n",
       "4      2009              N  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAvSdxKBDPWe"
   },
   "source": [
    "### **2.3 Fix Data Types** <font color = red>[3 marks]</font>\n",
    "Carefully examine the dataset and identify columns that contain date or time information but are not stored as the appropriate data type. Convert these columns to the correct datetime data type to enable proper analysis and manipulation of temporal information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3018,
   "metadata": {
    "id": "WIycvsINDPWe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     00:00:00\n",
       "1     00:00:00\n",
       "2     00:00:00\n",
       "3     00:00:00\n",
       "4     00:00:00\n",
       "5     00:00:00\n",
       "6     00:00:00\n",
       "7     00:00:00\n",
       "8     00:00:00\n",
       "9     00:00:00\n",
       "10    00:00:00\n",
       "11    00:00:00\n",
       "12    00:00:00\n",
       "13    00:00:00\n",
       "14    00:00:00\n",
       "15    00:00:00\n",
       "16    00:00:00\n",
       "17    00:00:00\n",
       "18    00:00:00\n",
       "19    00:00:00\n",
       "20    00:00:00\n",
       "21    00:00:00\n",
       "22    00:00:00\n",
       "23    00:00:00\n",
       "24    00:00:00\n",
       "25    00:00:00\n",
       "26    00:00:00\n",
       "27    00:00:00\n",
       "28    00:00:00\n",
       "29    00:00:00\n",
       "Name: incident_hour_of_the_day, dtype: object"
      ]
     },
     "execution_count": 3018,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix the data types of the columns with incorrect data types\n",
    "df['policy_bind_date'] = pd.to_datetime(df['policy_bind_date'])\n",
    "df['incident_date'] = pd.to_datetime(df['incident_date'])\n",
    "df['incident_hour_of_the_day']=pd.to_datetime(df['incident_hour_of_the_day']).dt.time\n",
    "df['incident_hour_of_the_day'].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3019,
   "metadata": {
    "id": "kl0jWZNEDPWe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 35 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   months_as_customer           1000 non-null   int64         \n",
      " 1   age                          1000 non-null   int64         \n",
      " 2   policy_number                1000 non-null   int64         \n",
      " 3   policy_bind_date             1000 non-null   datetime64[ns]\n",
      " 4   policy_state                 1000 non-null   object        \n",
      " 5   policy_csl                   1000 non-null   object        \n",
      " 6   policy_deductable            1000 non-null   int64         \n",
      " 7   policy_annual_premium        1000 non-null   float64       \n",
      " 8   umbrella_limit               1000 non-null   int64         \n",
      " 9   insured_zip                  1000 non-null   int64         \n",
      " 10  insured_sex                  1000 non-null   object        \n",
      " 11  insured_occupation           1000 non-null   object        \n",
      " 12  insured_relationship         1000 non-null   object        \n",
      " 13  capital-gains                1000 non-null   int64         \n",
      " 14  incident_date                1000 non-null   datetime64[ns]\n",
      " 15  incident_type                1000 non-null   object        \n",
      " 16  collision_type               822 non-null    object        \n",
      " 17  incident_severity            1000 non-null   object        \n",
      " 18  authorities_contacted        909 non-null    object        \n",
      " 19  incident_state               1000 non-null   object        \n",
      " 20  incident_city                1000 non-null   object        \n",
      " 21  incident_location            1000 non-null   object        \n",
      " 22  incident_hour_of_the_day     1000 non-null   object        \n",
      " 23  number_of_vehicles_involved  1000 non-null   int64         \n",
      " 24  property_damage              640 non-null    object        \n",
      " 25  bodily_injuries              1000 non-null   int64         \n",
      " 26  witnesses                    1000 non-null   int64         \n",
      " 27  police_report_available      657 non-null    object        \n",
      " 28  total_claim_amount           1000 non-null   int64         \n",
      " 29  injury_claim                 1000 non-null   int64         \n",
      " 30  property_claim               1000 non-null   int64         \n",
      " 31  vehicle_claim                1000 non-null   int64         \n",
      " 32  auto_model                   1000 non-null   object        \n",
      " 33  auto_year                    1000 non-null   int64         \n",
      " 34  fraud_reported               1000 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(15), object(17)\n",
      "memory usage: 273.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the features of the data again\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXS8rflQDPWe"
   },
   "source": [
    "## **3. Train-Validation Split** <font color = red>[5 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qOELXFYDPWe"
   },
   "source": [
    "### **3.1 Import required libraries**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3022,
   "metadata": {
    "id": "-vJKP7g0DPWe"
   },
   "outputs": [],
   "source": [
    "# Import train-test-split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MdKqcZ-DPWe"
   },
   "source": [
    "### **3.2 Define feature and target variables** <font color = red>[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3024,
   "metadata": {
    "id": "qacdKTt1DPWj"
   },
   "outputs": [],
   "source": [
    "# Put all the feature variables in X\n",
    "X= df.drop('fraud_reported', axis=1)\n",
    "# Put the target variable in y\n",
    "Y = df['fraud_reported']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2JaDNlsDPWj"
   },
   "source": [
    "### **3.3 Split the data** <font color=\"red\">[3 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3026,
   "metadata": {
    "id": "7_mMlbt7DPWj"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into 70% train and 30% validation and use stratification on the target variable\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,train_size=0.7,test_size = 0.3, random_state = 100)\n",
    "# Reset index for all train and test sets\n",
    "X_train=X_train.reset_index(drop=True)\n",
    "X_test=X_test.reset_index(drop=True)\n",
    "Y_train=Y_train.reset_index(drop=True)\n",
    "Y_test=Y_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4E_xpebIDPWk"
   },
   "source": [
    "## **4. EDA on training data** <font color = red>[20 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDNn7iBADPWk"
   },
   "source": [
    "### **4.1 Perform univariate analysis** <font color = red>[5 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVLeqhcADPWk"
   },
   "source": [
    "#### **4.1.1** Identify and select numerical columns from training data for univariate analysis <font color = \"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3078,
   "metadata": {
    "id": "bR9ulzRsDPWk"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('age', 'policy_annual_premium', 'umbrella_limit', 'capital-gains', 'number_of_vehicles_involved', 'bodily_injuries', 'witnesses', 'total_claim_amount', 'injury_claim', 'property_claim', 'vehicle_claim')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\AIProject\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('age', 'policy_annual_premium', 'umbrella_limit', 'capital-gains', 'number_of_vehicles_involved', 'bodily_injuries', 'witnesses', 'total_claim_amount', 'injury_claim', 'property_claim', 'vehicle_claim')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3078], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Select numerical columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m numeric_columns\u001b[38;5;241m=\u001b[39mX_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolicy_annual_premium\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumbrella_limit\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapital-gains\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_of_vehicles_involved\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbodily_injuries\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwitnesses\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_claim_amount\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minjury_claim\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty_claim\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvehicle_claim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mC:\\AIProject\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\AIProject\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: ('age', 'policy_annual_premium', 'umbrella_limit', 'capital-gains', 'number_of_vehicles_involved', 'bodily_injuries', 'witnesses', 'total_claim_amount', 'injury_claim', 'property_claim', 'vehicle_claim')"
     ]
    }
   ],
   "source": [
    "# Select numerical columns\n",
    "X_train['age', 'policy_annual_premium','umbrella_limit','capital-gains','number_of_vehicles_involved','bodily_injuries','witnesses','total_claim_amount','injury_claim','property_claim','vehicle_claim']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wP4icMhPDPWk"
   },
   "source": [
    "#### **4.1.2** Visualise the distribution of selected numerical features using appropriate plots to understand their characteristics <font color = \"red\">[4 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ny7woMrmDPWk"
   },
   "outputs": [],
   "source": [
    "# Plot all the numerical columns to understand their distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4UAw5pDDPWl"
   },
   "source": [
    "### **4.2 Perform correlation analysis** <font color=\"red\">[3 Marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySJiTDdxDPWl"
   },
   "source": [
    " Investigate the relationships between numerical features to identify potential multicollinearity or dependencies. Visualise the correlation structure using an appropriate method to gain insights into feature relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xadGQK7DPWl"
   },
   "outputs": [],
   "source": [
    "# Create correlation matrix for numerical columns\n",
    "\n",
    "# Plot Heatmap of the correlation matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHQ3du-9DPWl"
   },
   "source": [
    "### **4.3 Check class balance** <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTkJHl0xDPWm"
   },
   "source": [
    "Examine the distribution of the target variable to identify potential class imbalances using visualisation for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1QrXZdhDPWm"
   },
   "outputs": [],
   "source": [
    "# Plot a bar chart to check class balance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFhVKzRHDPWn"
   },
   "source": [
    "### **4.4 Perform bivariate analysis** <font color=\"red\">[10 Marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0WjamQXDPWn"
   },
   "source": [
    "#### **4.4.1** Target likelihood analysis for categorical variables. <font color=\"red\">[5 Marks]</font>\n",
    "Investigate the relationships between categorical features and the target variable by analysing the target event likelihood (for the `'Y'` event) for each level of every relevant categorical feature. Through this analysis, identify categorical features that do not contribute much in explaining the variation in the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1OQJrO5guyw"
   },
   "outputs": [],
   "source": [
    "# Write a function to calculate and analyse the target variable likelihood for categorical features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6oeg9naDPWo"
   },
   "source": [
    "#### **4.4.2** Explore the relationships between numerical features and the target variable to understand their impact on the target outcome using appropriate visualisation techniques to identify trends and potential interactions. <font color=\"red\">[5 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVXoNozGDPWo"
   },
   "outputs": [],
   "source": [
    "# Visualise the relationship between numerical features and the target variable to understand their impact on the target outcome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVV4m9OiDPWo"
   },
   "source": [
    "## **5. EDA on validation data** <font color = red>[OPTIONAL]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvF11y45DPWo"
   },
   "source": [
    "### **5.1 Perform univariate analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krLtfiOBDPWo"
   },
   "source": [
    "#### **5.1.1** Identify and select numerical columns from training data for univariate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RURn5Dp1DPWo"
   },
   "outputs": [],
   "source": [
    "# Select numerical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a41PWZrNDPWp"
   },
   "source": [
    "#### **5.1.2** Visualise the distribution of selected numerical features using appropriate plots to understand their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUoPrry8DPWp"
   },
   "outputs": [],
   "source": [
    "# Plot all the numerical columns to understand their distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhvTVXiwDPWp"
   },
   "source": [
    "### **5.2 Perform correlation analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5tDAjsNDPWp"
   },
   "source": [
    " Investigate the relationships between numerical features to identify potential multicollinearity or dependencies. Visualise the correlation structure using an appropriate method to gain insights into feature relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-b6CSy1DPWp"
   },
   "outputs": [],
   "source": [
    "# Create correlation matrix for numerical columns\n",
    "\n",
    "# Plot Heatmap of the correlation matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2ww_JH7DPWp"
   },
   "source": [
    "### **5.3 Check class balance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddcn-VSADPWp"
   },
   "source": [
    "Examine the distribution of the target variable to identify potential class imbalances. Visualise the distribution for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Yvfw9F2DPWq"
   },
   "outputs": [],
   "source": [
    "# Plot a bar chart to check class balance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pDlcXHxDPWq"
   },
   "source": [
    "### **5.4 Perform bivariate analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0UT1kLHDPWq"
   },
   "source": [
    "#### **5.4.1** Target likelihood analysis for categorical variables.\n",
    "Investigate the relationships between categorical features and the target variable by analysing the target event likelihood (for the `'Y'` event) for each level of every relevant categorical feature. Through this analysis, identify categorical features that do not contribute much in explaining the variation in the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMe7hHDcDPWr"
   },
   "outputs": [],
   "source": [
    "# Write a function to calculate and analyse the target variable likelihood for categorical features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCNILHjCDPWr"
   },
   "source": [
    "#### **5.4.2** Explore the relationships between numerical features and the target variable to understand their impact on the target outcome. Utilise appropriate visualisation techniques to identify trends and potential interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhQl8TJ9DPWr"
   },
   "outputs": [],
   "source": [
    "# Visualise the relationship between numerical features and the target variable to understand their impact on the target outcome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVb5a63HDPWr"
   },
   "source": [
    "## **6. Feature Engineering** <font color = red>[25 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1-lpq1iDPWs"
   },
   "source": [
    "### **6.1 Perform resampling** <font color=\"red\">[3 Marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vV6fEzAADPWs"
   },
   "source": [
    "Handle class imbalance in the training data by applying resampling technique.\n",
    "\n",
    "Use the **RandomOverSampler** technique to balance the data and handle class imbalance. This method increases the number of samples in the minority class by randomly duplicating them, creating synthetic data points with similar characteristics. This helps prevent the model from being biased toward the majority class and improves its ability to predict the minority class more accurately.\n",
    "\n",
    "**Note:** You can try other resampling techniques to handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijz0X5bGDPWs"
   },
   "outputs": [],
   "source": [
    "# Import RandomOverSampler from imblearn library\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Perform resampling on training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ7nY4SLDPWs"
   },
   "source": [
    "### **6.2 Feature Creation** <font color=\"red\">[4 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdDUn_sVDPWs"
   },
   "source": [
    "Create new features from existing ones to enhance the model's ability to capture patterns in the data. This may involve deriving features from date/time columns, combining features, or creating interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beiDdjl7DPWs"
   },
   "outputs": [],
   "source": [
    "# Create new features based on your understanding for both training and validation data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbQ6FhLUDPWt"
   },
   "source": [
    "### **6.3 Handle redundant columns** <font color=\"red\">[3 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zs_uzd9VDPWt"
   },
   "source": [
    "Analyse the data to identify features that may be redundant or contribute minimal information toward predicting the target variable and drop them.\n",
    "\n",
    "- You can consider features that exhibit high correlation with other variables, which you may have observed during the EDA phase.\n",
    "- Features that don't strongly influence the prediction, which you may have observed during the EDA phase.\n",
    "- Categorical columns with low value counts for some levels can be remapped to reduce number of unique levels, and features with very high counts for just one level may be removed, as they resemble unique identifier columns and do not provide substantial predictive value.\n",
    "- Additionally, eliminate any columns from which the necessary features have already been extracted in the preceding step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Fy0Rw1BDPWt"
   },
   "outputs": [],
   "source": [
    "# Drop redundant columns from training and validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVYVBV27DPWt"
   },
   "outputs": [],
   "source": [
    "# Check the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxA7dZ0UDPWt"
   },
   "source": [
    "### **6.4 Combine values in Categorical Columns** <font color=\"red\">[6 Marks]</font>\n",
    "During the EDA process, categorical columns with multiple unique values may be identified. To enhance model performance, it is essential to refine these categorical features by grouping values that have low frequency or provide limited predictive information.\n",
    "\n",
    "Combine categories that occur infrequently or exhibit similar behavior to reduce sparsity and improve model generalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OF7Y35dDPWt"
   },
   "outputs": [],
   "source": [
    "# Combine categories that have low frequency or provide limited predictive information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2vnyJqYDPWt"
   },
   "source": [
    "### **6.5 Dummy variable creation** <font color=\"red\">[6 Marks]</font>\n",
    "Transform categorical variables into numerical representations using dummy variables. Ensure consistent encoding between training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQHnbRB_DPWt"
   },
   "source": [
    "#### **6.5.1** Identify categorical columns for dummy variable creation <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YCR73H4VDPWt"
   },
   "outputs": [],
   "source": [
    "# Identify the categorical columns for creating dummy variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcCgF0lsDPWu"
   },
   "source": [
    "#### **6.5.2** Create dummy variables for categorical columns in training data <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JA8seldpDPWu"
   },
   "outputs": [],
   "source": [
    "# Create dummy variables using the 'get_dummies' for categorical columns in training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbLlOiYcDPWu"
   },
   "source": [
    "#### **6.5.3** Create dummy variables for categorical columns in validation data <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvQ4n9yaDPWu"
   },
   "outputs": [],
   "source": [
    "# Create dummy variables using the 'get_dummies' for categorical columns in validation data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg5crIDKDPWu"
   },
   "source": [
    "#### **6.5.4** Create dummy variable for dependent feature in training and validation data <font color = \"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyreaJQXDPWu"
   },
   "outputs": [],
   "source": [
    "# Create dummy variable for dependent feature in training data\n",
    "\n",
    "# Create dummy variable for dependent feature in validation data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USXyE8QSDPWu"
   },
   "source": [
    "### **6.6 Feature scaling** <font color = red>[3 marks]</font>\n",
    "Scale numerical features to a common range to prevent features with larger values from dominating the model.  Choose a scaling method appropriate for the data and the chosen model. Apply the same scaling to both training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfE4LXqXDPWu"
   },
   "outputs": [],
   "source": [
    "# Import the necessary scaling tool from scikit-learn\n",
    "\n",
    "# Scale the numeric features present in the training data\n",
    "\n",
    "# Scale the numeric features present in the validation data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqIhEkpxDPWu"
   },
   "source": [
    "## **7. Model Building** <font color = red>[50 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2OLtpZWUmgS"
   },
   "source": [
    "In this task, you will be building two machine learning models: Logistic Regression and Random Forest. Each model will go through a structured process to ensure optimal performance. The key steps for each model are outlined below:\n",
    "\n",
    "**Logistic Regression Model**\n",
    "- Feature Selection using RFECV – Identify the most relevant features using Recursive Feature Elimination with Cross-Validation.\n",
    "- Model Building and Multicollinearity Assessment – Build the logistic regression model and analyse statistical aspects such as p-values and VIFs to detect multicollinearity.\n",
    "- Model Training and Evaluation on Training Data – Fit the model on the training data and assess initial performance.\n",
    "- Finding the Optimal Cutoff – Determine the best probability threshold by analysing the sensitivity-specificity tradeoff and precision-recall tradeoff.\n",
    "- FInal Prediction and Evaluation on Training Data using the Optimal Cutoff – Generate final predictions using the selected cutoff and evaluate model performance.\n",
    "\n",
    "**Random Forest Model**\n",
    "- Get Feature Importances - Obtain the importance scores for each feature and select the important features to train the model.\n",
    "- Model Evaluation on Training Data – Assess performance metrics on the training data.\n",
    "- Check Model Overfitting using Cross-Validation – Evaluate generalisation by performing cross-validation.\n",
    "- Hyperparameter Tuning using Grid Search – Optimise model performance by fine-tuning hyperparameters.\n",
    "- Final Model and Evaluation on Training Data – Train the final model using the best parameters and assess its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwQl23_eDPWx"
   },
   "source": [
    "### **7.1 Feature selection** <font color = red>[4 marks]</font>\n",
    "Identify and select the most relevant features for building a logistic regression model using Recursive Feature Elimination with Cross-Validation (RFECV)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7oRIQMhDPWy"
   },
   "source": [
    "#### **7.1.1** Import necessary libraries <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzQF3EyIDPWy"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1sHmcZKDPWy"
   },
   "source": [
    "#### **7.1.2** Perform feature selection <font color=\"red\">[2 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKRnzy8sDPWy"
   },
   "outputs": [],
   "source": [
    "# Apply RFECV to identify the most relevant features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1I0kn-9qDPWy"
   },
   "outputs": [],
   "source": [
    "# Display the features ranking by RFECV in a DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKdXnylEDPWz"
   },
   "source": [
    "#### **7.1.2** Retain the selected features <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8TkAe72DPWz"
   },
   "outputs": [],
   "source": [
    "# Put columns selected by RFECV into variable 'col'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8zNEaKcDPWz"
   },
   "source": [
    "### **7.2 Build Logistic Regression Model** <font color = red>[12 marks]</font>\n",
    "After selecting the optimal features using RFECV, utilise these features to build a logistic regression model with Statsmodels. This approach enables a detailed statistical analysis of the model, including the assessment of p-values and Variance Inflation Factors (VIFs). Evaluating these metrics is crucial for detecting multicollinearity and ensuring that the selected predictors are not highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXwl9DO3DPWz"
   },
   "source": [
    "#### **7.2.1** Select relevant features and add constant in training data <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kF5g0yScDPWz"
   },
   "outputs": [],
   "source": [
    "# Select only the columns selected by RFECV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBzSiNhrDPWz"
   },
   "outputs": [],
   "source": [
    "# Import statsmodels and add constant\n",
    "\n",
    "# Check the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jc9wYqe8DPW0"
   },
   "source": [
    "#### **7.2.2** Fit logistic regression model <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VTpvsZsDPW0"
   },
   "outputs": [],
   "source": [
    "# Fit a logistic Regression model on X_train after adding a constant and output the summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBd9hyWgDPW0"
   },
   "source": [
    "**Model Interpretation**\n",
    "\n",
    "The output summary table will provide the features used for building model along with coefficient of each of the feature and their p-value. The p-value in a logistic regression model is used to assess the statistical significance of each coefficient. Lesser the p-value, more significant the feature is in the model.\n",
    "\n",
    "A positive coefficient will indicate that an increase in the value of feature would increase the odds of the event occurring. On the other hand, a negative coefficient means the opposite, i.e, an increase in the value of feature would decrease the odds of the event occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnhgDNCNDPW0"
   },
   "source": [
    "Now check VIFs for presence of multicollinearity in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLTRjCqCDPW0"
   },
   "source": [
    "#### **7.2.3** Evaluate VIF of features to assess multicollinearity <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOIppRgGDPW0"
   },
   "outputs": [],
   "source": [
    "# Import 'variance_inflation_factor'\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xwb2dA9XDPW0"
   },
   "outputs": [],
   "source": [
    "# Make a VIF DataFrame for all the variables present\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RMrfSNPDPW1"
   },
   "source": [
    "Proceed to the next step if p-values and VIFs are within acceptable ranges. If you observe high p-values or VIFs, drop the features and retrain the model. <font color=\"red\">[THIS IS OPTIONAL]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68j2g6bRDPW1"
   },
   "source": [
    "#### **7.2.4** Make predictions on training data <font color = \"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DT1M3O9DPW1"
   },
   "outputs": [],
   "source": [
    "# Predict the probabilities on the training data\n",
    "\n",
    "# Reshape it into an array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_j4gJDUzDPW1"
   },
   "source": [
    "#### **7.2.5** Create a DataFrame that includes actual fraud reported flags, predicted probabilities, and a column indicating predicted classifications based on a cutoff value of 0.5 <font color=\"red\">[1 Mark]</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDaW7LS_DPW1"
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame containing the actual fraud reported flag and the probabilities predicted by the model\n",
    "\n",
    "# Create new column indicating predicted classifications based on a cutoff value of 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rXpNOgtDPW1"
   },
   "source": [
    "**Model performance evaluation**\n",
    "\n",
    "Evaluate the performance of the model based on predictions made on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cornkRdjDPW2"
   },
   "source": [
    "#### **7.2.6** Check the accuracy of the model <font color = \"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0tyT2xgDPW2"
   },
   "outputs": [],
   "source": [
    "# Import metrics from sklearn for evaluation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Check the accuracy of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQPieExsDPW2"
   },
   "source": [
    "#### **7.2.7** Create a confusion matrix based on the predictions made on the training data <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1v1XZbNkDPW2"
   },
   "outputs": [],
   "source": [
    "# Create confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVWR_SjqKPQF"
   },
   "source": [
    "#### **7.2.8** Create variables for true positive, true negative, false positive and false negative <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaXLtV-HKPgY"
   },
   "outputs": [],
   "source": [
    "# Create variables for true positive, true negative, false positive and false negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkO5we1NDPW3"
   },
   "source": [
    "#### **7.2.9** Calculate sensitivity, specificity, precision, recall and F1-score <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5GpJK5CDPW3"
   },
   "outputs": [],
   "source": [
    "# Calculate the sensitivity\n",
    "\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "\n",
    "# Calculate Precision\n",
    "\n",
    "\n",
    "# Calculate Recall\n",
    "\n",
    "\n",
    "# Calculate F1 Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIFdLeULDPW4"
   },
   "source": [
    "### **7.3 Find the Optimal Cutoff** <font color = red>[12 marks]</font>\n",
    "Find the optimal cutoff to improve model performance by evaluating various cutoff values and their impact on relevant metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-un_98BlDPW4"
   },
   "source": [
    "#### **7.3.1** Plot ROC Curve  to visualise the trade-off between true positive rate and false positive rate across different classification thresholds <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfRY65pZDPW5"
   },
   "outputs": [],
   "source": [
    "# Import libraries or function to plot the ROC curve\n",
    "\n",
    "\n",
    "# Define ROC function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGlAWkJDDPW6"
   },
   "outputs": [],
   "source": [
    "# Call the ROC function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFPV1EBDDPW6"
   },
   "source": [
    "**Sensitivity and Specificity tradeoff**\n",
    "\n",
    "After analysing the area under the curve of the ROC, check the sensitivity and specificity tradeoff to find the optimal cutoff point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjcQP2BzDPW6"
   },
   "source": [
    "#### **7.3.2** Predict on training data at various probability cutoffs <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1UMUMNODPW6"
   },
   "outputs": [],
   "source": [
    "# Create columns with different probability cutoffs to explore the impact of cutoff on model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EFEKx21DPW6"
   },
   "source": [
    "#### **7.3.3** Plot accuracy, sensitivity, specificity at different values of probability cutoffs <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsjuXoXtDPW6"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to see the values of accuracy, sensitivity, and specificity at different values of probability cutoffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4og5facDPW7"
   },
   "outputs": [],
   "source": [
    "# Plot accuracy, sensitivity, and specificity at different values of probability cutoffs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6C-ScQ1DPW7"
   },
   "source": [
    "#### **7.3.4** Create a column for final prediction based on optimal cutoff <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1p-z0A9wDPW7"
   },
   "outputs": [],
   "source": [
    "# Create a column for final prediction based on the optimal cutoff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jEQC7QlDPW7"
   },
   "source": [
    "#### **7.3.5** Calculate the accuracy <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XARhijiDPW7"
   },
   "outputs": [],
   "source": [
    "# Check the accuracy now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsgvpYa3DPW-"
   },
   "source": [
    "#### **7.3.6** Create confusion matrix <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuRtey6YDPW-"
   },
   "outputs": [],
   "source": [
    "# Create the confusion matrix once again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbfa0CsbDPW-"
   },
   "source": [
    "#### **7.3.7** Create variables for true positive, true negative, false positive and false negative <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAQncHXtDPW_"
   },
   "outputs": [],
   "source": [
    "# Create variables for true positive, true negative, false positive and false negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7KXFHRnDPW_"
   },
   "source": [
    "#### **7.3.8** Calculate sensitivity, specificity, precision, recall and F1-score of the model <font color=\"red\">[2 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "958ly8K8DPW_"
   },
   "outputs": [],
   "source": [
    "# Calculate the sensitivity\n",
    "\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "\n",
    "# Calculate Precision\n",
    "\n",
    "\n",
    "# Calculate Recall\n",
    "\n",
    "\n",
    "# Calculate F1 Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dNjDGtNDPXA"
   },
   "source": [
    "**Precision and Recall tradeoff**\n",
    "\n",
    "Check optimal cutoff value by plotting precision-recall curve, and adjust the cutoff based on precision and recall tradeoff if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGKKbLQgDPXA"
   },
   "outputs": [],
   "source": [
    "# Import precision-recall curve function\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4_-ZTXYDPXB"
   },
   "source": [
    "#### **7.3.9** Plot precision-recall curve <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wj2qr5FSDPXB"
   },
   "outputs": [],
   "source": [
    "# Plot precision-recall curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdNY3cNPDPXB"
   },
   "source": [
    "### **7.4 Build Random Forest Model** <font color = red>[12 marks]</font>\n",
    "Now that you have built a logistic regression model, let's move on to building a random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sS2Hc10fDPXC"
   },
   "source": [
    "#### **7.4.1** Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6duSoHlDPXC"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Euc5ukLDPXC"
   },
   "source": [
    "#### **7.4.2** Build the random forest model <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ouCc_YFDPXC"
   },
   "outputs": [],
   "source": [
    "# Build a base random forest model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wr3ExsTgUSKl"
   },
   "source": [
    "#### **7.4.3** Get feature importance scores and select important features <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSnQ3xQL__gV"
   },
   "outputs": [],
   "source": [
    "# Get feature importance scores from the trained model\n",
    "\n",
    "# Create a DataFrame to visualise the importance scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQIR2yUqxNVI"
   },
   "outputs": [],
   "source": [
    "# Select features with high importance scores\n",
    "\n",
    "# Create a new training data with only the selected features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTzZ1YnhU9Dt"
   },
   "source": [
    "#### **7.4.4** Train the model with selected features <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IeU6JcgJUnPs"
   },
   "outputs": [],
   "source": [
    "# Fit the model on the training data with selected features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_5Fk-9bDPXG"
   },
   "source": [
    "#### **7.4.5** Generate predictions on the training data <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TO6AGoPFDPXG"
   },
   "outputs": [],
   "source": [
    "# Generate predictions on training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5ApUsKlDPXH"
   },
   "source": [
    "#### **7.4.6** Check accuracy of the model <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2zmn36dDPXH"
   },
   "outputs": [],
   "source": [
    "# Check accuracy of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_e5FElrDPXH"
   },
   "source": [
    "#### **7.4.7** Create confusion matrix <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJIGPNTaDPXI"
   },
   "outputs": [],
   "source": [
    "# Create the confusion matrix to visualise the performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rY3mFM8CDPXI"
   },
   "source": [
    "#### **7.4.8** Create variables for true positive, true negative, false positive and false negative <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9Ehc0vcDPXI"
   },
   "outputs": [],
   "source": [
    "# Create variables for true positive, true negative, false positive and false negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NSOsFxRDPXJ"
   },
   "source": [
    "#### **7.4.9** Calculate sensitivity, specificity, precision, recall and F1-score of the model <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3wJsKu3DPXJ"
   },
   "outputs": [],
   "source": [
    "# Calculate the sensitivity\n",
    "\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "\n",
    "# Calculate Precision\n",
    "\n",
    "\n",
    "# Calculate Recall\n",
    "\n",
    "\n",
    "# Calculate F1 Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6Jax54VDPXJ"
   },
   "source": [
    "#### **7.4.10** Check if the model is overfitting training data using cross validation <font color = \"red\">[2 marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42-huob6DPXJ"
   },
   "outputs": [],
   "source": [
    "# Use cross validation to check if the model is overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNxYrAKZDPXJ"
   },
   "source": [
    "### **7.5 Hyperparameter Tuning** <font color = red>[10 Marks]</font>\n",
    " Enhance the performance of the random forest model by systematically exploring and selecting optimal hyperparameter values using grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnBcYjbQDPXK"
   },
   "source": [
    "#### **7.5.1** Use grid search to find the best hyperparameter values <font color = red>[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTLCDfb4DPXK"
   },
   "outputs": [],
   "source": [
    "# Use grid search to find the best hyperparamter values\n",
    "\n",
    "# Best Hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrGoY46TDPXK"
   },
   "source": [
    "#### **7.5.2** Build a random forest model based on hyperparameter tuning results <font color = red>[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yxPaaDxDPXK"
   },
   "outputs": [],
   "source": [
    "# Building random forest model based on results of hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJ4gQ2m0DPXK"
   },
   "source": [
    "#### **7.5.3** Make predictions on training data <font color = red>[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTE3p2rCDPXL"
   },
   "outputs": [],
   "source": [
    "# Make predictions on training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbfSJpEuDPXL"
   },
   "source": [
    "#### **7.5.4** Check accuracy of Random Forest Model <font color = red>[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItpV-JYkDPXL"
   },
   "outputs": [],
   "source": [
    "# Check the accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-t6Hme3DPXL"
   },
   "source": [
    "#### **7.5.5** Create confusion matrix <font color = red>[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdteUZXzDPXL"
   },
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEUtsRafDPXL"
   },
   "source": [
    "#### **7.5.6** Create variables for true positive, true negative, false positive and false negative <font color = red>[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aeUhFSWDPXM"
   },
   "outputs": [],
   "source": [
    "# Create variables for true positive, true negative, false positive and false negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwDnBdjnDPXM"
   },
   "source": [
    "#### **7.5.7** Calculate sensitivity, specificity, precision, recall and F1-score of the model <font color = red>[3 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxPHj1NjDPXM"
   },
   "outputs": [],
   "source": [
    "# Calculate the sensitivity\n",
    "\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "\n",
    "# Calculate Precision\n",
    "\n",
    "\n",
    "# Calculate Recall\n",
    "\n",
    "\n",
    "# Calculate F1-Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUEvyADyDPXM"
   },
   "source": [
    "## **8. Prediction and Model Evaluation** <font color = red>[20 marks]</font>\n",
    "Use the model from the previous step to make predictions on the validation data with the optimal cutoff. Then evaluate the model's performance using metrics such as accuracy, sensitivity, specificity, precision, and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQuMB-P1DPXM"
   },
   "source": [
    "### **8.1 Make predictions over validation data using logistic regression model** <font color = red>[10 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wuz5v3TYDPXM"
   },
   "source": [
    "#### **8.1.1** Select relevant features for validation data and add constant <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AbB-x3aDPXM"
   },
   "outputs": [],
   "source": [
    "# Select the relevant features for validation data\n",
    "\n",
    "# Add constant to X_validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzpawlMLDPXM"
   },
   "source": [
    "#### **8.1.2** Make predictions over validation data <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CmoAZJODPXM"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the validation data and store it in the variable 'y_validation_pred'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8qyn8xvDPXM"
   },
   "source": [
    "#### **8.1.3** Create DataFrame with actual values and predicted values for validation data <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Zx8RBFVDPXN"
   },
   "outputs": [],
   "source": [
    "#  Create DataFrame with actual values and predicted values for validation data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_kC6wEPDPXN"
   },
   "source": [
    "#### **8.1.4** Make final prediction based on cutoff value <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ge-EC74DPXN"
   },
   "outputs": [],
   "source": [
    "# Make final predictions on the validation data using the optimal cutoff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bt7sm55QDPXN"
   },
   "source": [
    "#### **8.1.5** Check the accuracy of logistic regression model on validation data <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81tEKwwsDPXN"
   },
   "outputs": [],
   "source": [
    "# Check the accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE8ZnagdDPXN"
   },
   "source": [
    "#### **8.1.6** Create confusion matrix <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjkkexqrDPXN"
   },
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSqBZOrYDPXN"
   },
   "source": [
    "#### **8.1.7** Create variables for true positive, true negative, false positive and false negative <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzH_sFeoDPXN"
   },
   "outputs": [],
   "source": [
    "# Create variables for true positive, true negative, false positive and false negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Mkn6DUwDPXN"
   },
   "source": [
    "#### **8.1.8** Calculate sensitivity, specificity, precision, recall and f1 score of the model <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCqNW4t3DPXO"
   },
   "outputs": [],
   "source": [
    "# Calculate the sensitivity\n",
    "\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "\n",
    "# Calculate Precision\n",
    "\n",
    "\n",
    "# Calculate Recall\n",
    "\n",
    "\n",
    "# Calculate F1 Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wTVm8V_DPXO"
   },
   "source": [
    "### **8.2 Make predictions over validation data using random forest model** <font color = red>[10 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDgbDTfIDPXO"
   },
   "source": [
    "#### **8.2.1** Select the important features and make predictions over validation data <font color=\"red\">[2 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhtKprsQDPXO"
   },
   "outputs": [],
   "source": [
    "# Select the relevant features for validation data\n",
    "\n",
    "# Make predictions on the validation data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUbtP7CADPXO"
   },
   "source": [
    "#### **8.2.2** Check accuracy of random forest model <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJyVOpLlDPXO"
   },
   "outputs": [],
   "source": [
    "# Check accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spUa4VBfDPXO"
   },
   "source": [
    "#### **8.2.3** Create confusion matrix <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXJVNVrSDPXO"
   },
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuUdgVYSDPXO"
   },
   "source": [
    "#### **8.2.4** Create variables for true positive, true negative, false positive and false negative <font color=\"red\">[1 Mark]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UT7lU5CWDPXO"
   },
   "outputs": [],
   "source": [
    "# Create variables for true positive, true negative, false positive and false negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAjovvF4DPXO"
   },
   "source": [
    "#### **8.2.5** Calculate sensitivity, specificity, precision, recall and F1-score of the model <font color=\"red\">[5 Marks]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1PYzDaWDPXO"
   },
   "outputs": [],
   "source": [
    "# Calculate Sensitivity\n",
    "\n",
    "\n",
    "# Calculate Specificity\n",
    "\n",
    "\n",
    "# Calculate Precision\n",
    "\n",
    "\n",
    "# Calculate Recall\n",
    "\n",
    "\n",
    "# Calculate F1-score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nENAdFWhDPXP"
   },
   "source": [
    "## **Evaluation and Conclusion**\n",
    "Write the conclusion."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1SIhxHs7kl3qt0VU3gGAAt_k_NQTvuqmc",
     "timestamp": 1740041215388
    },
    {
     "file_id": "1wef6jk_PrklarfJ5GA9FoyCAiKkArPCw",
     "timestamp": 1739780524071
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
